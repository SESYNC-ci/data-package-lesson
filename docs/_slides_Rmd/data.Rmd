---

---

## Data

Consistency is key when managing your data!

1. At a minimum, use the same terms to refer to the same things throughout your data.

2. Potentially use a discipline-wide published vocabulary (ex: [hydrological controlled vocab.]: http://vocabulary.odm2.org/)

===

### Naming data files - review from basic-R-lesson

Bad:
"CeNsus data*2ndTry 2/15/2017.csv"   

Good:
"census_data_try_2.csv"  

```{r}
library(tidyverse)

cen_dat <- read_csv("data/ACS/????????????????????.csv")
####################NOTEEEEEE: make "messy" dataset for this demo 
```

===

### Formatting data - review from data-manipulation-R-lesson

1. One table/file for each type of observation.
2. Each variable has its own column.
3. Each observation has its own row.
4. Each value has its own cell.

Downstream operations/analysis require tidy data. You can work towards read-to-analyze data incrementally,
documenting the intermediate data and steps you took in your scripts.  This can be a powerful accelerator 
for your analysis both now and in the future.  

===

Let's do a few checks to see if our data is tidy.

 - make sure data is long
 - make sure blanks are NA or some other standard
```{}
head(cen_dat)
tail(cen_dat)
```    
 
 - check date format
```{}
str(cen_dat)    
```  

 - check case, white space, etc.  
```{}
unique(cen_dat)     
```
    
===
    
### Outputting derived data - review from the basic-R-lesson
    
Because we followed the principle of one table/file for each type of observation, 
we have ???? tables to be written out to files now.  

```{}
write_csv()
```

===
    
### Versioning your derived data

maybe talk here about uploading a version of your data early on in your research data process, and then versioning the derived data in the repository, taking advantage of the repo-built-in unique ids for each new version of your data - may help address the issue of collaborators using different versions of the data for analysis?


