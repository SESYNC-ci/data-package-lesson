---
 
---

## Preparing Data for Publication

Both raw data and derived data (data you've assembled or processed in some way) from a project need to be neat and tidy before publication.  Following principles of tidy data from the beginning will make your workflows more efficient during a project, and will make it easier for others to understand and use your data once published.  However, if your data isn't yet tidy, you can make it tidier before you publish it.  
{:.notes} 

Consistency is key when managing your data!

===

1. At a minimum, use the same terms to refer to the same things throughout your data.

   - "origin", not "starting place", "beginning location", and "source"
   - "*Orcinus orca*", not "killer Whale", "Killer whale", "killer.whale", and "orca"

2. Consider using a discipline-wide published vocabulary if appropriate (ex: [hydrological controlled vocab.](http://vocabulary.odm2.org/))

===

### Naming data files 

__Bad:__  "CeNsus data*2ndTry 2/15/2017.csv"   

__Good:__  "census_data.csv"  

```{r, message = FALSE, handout = 0}
library(tidyverse)

stm_dat <- read_csv("data/StormEvents.csv")
```

===

### Formatting data

1. One table/file for each type of observation, e.g., a CSV file for storm events in the USA 
2. Each variable has its own column, e.g., month and location of a storm event are different columns in the file
3. Each observation has its own row, e.g., each storm event is represented by a row
4. Each value has its own cell

Downstream operations/analysis require tidy data.  

These principles closely map to best practices for “normalization” in database design.  R developer Hadley Wickham further describes the priciples of tidy data in this paper [(Wickham 2014)](http://www.jstatsoft.org/v59/i10/paper). 
{:.notes}

You can work towards ready-to-analyze data incrementally, documenting the intermediate data and cleaning steps you took in your scripts.  This can be a powerful accelerator for your analysis both now and in the future.  
{:.notes}

===

Let's do a few checks to see if our data is tidy.

 - make sure data meet criteria above
 - make sure blanks are NA or some other standard
 
```{r, eval = FALSE}
head(stm_dat)
tail(stm_dat)
```    

=== 

 - check date format
```{r, eval = FALSE}
str(stm_dat)    
```  

 - check case, white space, etc.  
```{r, eval = FALSE}
unique(stm_dat$EVENT_NARRATIVE)    
```

===
    
### Outputting derived data 
    
Because we followed the principle of one table/file for each type of observation, 
we have one table to be written out to a file now.  

```{r, handout = 0}
dir.create('storm_project', showWarnings = FALSE)
write_csv(stm_dat, "storm_project/StormEvents_d2006.csv")
```

===
    
### Versioning your derived data

Issue: Making sure you and your collaborators are using the same version of a dataset

One solution: version your data in a repository (more on this [later](#versioning-data))



